<!DOCTYPE html>
<html lang="de-DE" dir="ltr" itemscope itemtype="http://schema.org/Article">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.135.0">
    <meta name="generator" content="Relearn 6.4.1">
    <meta name="description" content="Hier finden Sie die Übungsblätter.
Bitte bearbeiten Sie vor der jeweiligen Sprechstunde das bereitgestellte Material (Skripte, Videos, Quizzes, Literatur, ...) und versuchen Sie vor der Sprechstunde das entsprechende Übungsblatt zu lösen, damit Sie in der der Sprechstunde Ihre Fragen zum Thema stellen können.
Übungsblatt: Perzeptron Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg Übungsblatt: Overfitting &amp; MLP Übungsblatt: Backpropagation Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL) Übungsblatt: Problemlösen, Suche Übungsblatt: Lokale Suche, GA Übungsblatt: Spiele Übungsblatt: Constraints Übungsblatt: Naive Bayes">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Praktikum/Übung">
    <meta name="twitter:description" content="Hier finden Sie die Übungsblätter.
Bitte bearbeiten Sie vor der jeweiligen Sprechstunde das bereitgestellte Material (Skripte, Videos, Quizzes, Literatur, ...) und versuchen Sie vor der Sprechstunde das entsprechende Übungsblatt zu lösen, damit Sie in der der Sprechstunde Ihre Fragen zum Thema stellen können.
Übungsblatt: Perzeptron Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg Übungsblatt: Overfitting &amp; MLP Übungsblatt: Backpropagation Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL) Übungsblatt: Problemlösen, Suche Übungsblatt: Lokale Suche, GA Übungsblatt: Spiele Übungsblatt: Constraints Übungsblatt: Naive Bayes">
    <meta property="og:url" content="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework.html">
    <meta property="og:title" content="Praktikum/Übung">
    <meta property="og:description" content="Hier finden Sie die Übungsblätter.
Bitte bearbeiten Sie vor der jeweiligen Sprechstunde das bereitgestellte Material (Skripte, Videos, Quizzes, Literatur, ...) und versuchen Sie vor der Sprechstunde das entsprechende Übungsblatt zu lösen, damit Sie in der der Sprechstunde Ihre Fragen zum Thema stellen können.
Übungsblatt: Perzeptron Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg Übungsblatt: Overfitting &amp; MLP Übungsblatt: Backpropagation Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL) Übungsblatt: Problemlösen, Suche Übungsblatt: Lokale Suche, GA Übungsblatt: Spiele Übungsblatt: Constraints Übungsblatt: Naive Bayes">
    <meta property="og:locale" content="de_DE">
    <meta property="og:type" content="website">
    <meta itemprop="name" content="Praktikum/Übung">
    <meta itemprop="description" content="Hier finden Sie die Übungsblätter.
Bitte bearbeiten Sie vor der jeweiligen Sprechstunde das bereitgestellte Material (Skripte, Videos, Quizzes, Literatur, ...) und versuchen Sie vor der Sprechstunde das entsprechende Übungsblatt zu lösen, damit Sie in der der Sprechstunde Ihre Fragen zum Thema stellen können.
Übungsblatt: Perzeptron Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg Übungsblatt: Overfitting &amp; MLP Übungsblatt: Backpropagation Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL) Übungsblatt: Problemlösen, Suche Übungsblatt: Lokale Suche, GA Übungsblatt: Spiele Übungsblatt: Constraints Übungsblatt: Naive Bayes">
    <meta itemprop="wordCount" content="78">
    <title>Praktikum/Übung</title>
    <link href="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework.html" rel="canonical" type="text/html" title="Praktikum/Übung">

    

    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/images/logo.png?1737742242" rel="icon" type="image/png">

    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fontawesome-all.min.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fontawesome-all.min.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/nucleus.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/auto-complete.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/auto-complete.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/perfect-scrollbar.min.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fonts.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fonts.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/theme.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/theme-auto.css?1737742242" rel="stylesheet" id="R-variant-style">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/chroma-auto.css?1737742242" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/variant.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/print.css?1737742242" rel="stylesheet" media="print">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/format-print.css?1737742242" rel="stylesheet">
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/variant.js?1737742242"></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='.';
      window.relearn.relBaseUri='..\/..\/..\/..\/..';
      window.relearn.absBaseUri='https:\/\/www.hsbi.de\/elearning\/data\/FH-Bielefeld\/lm_data\/lm_1358898';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.index_js_url="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/index.search.js?1737742242";
      // variant stuff
      window.variants && variants.init( [ 'auto', 'zen-light', 'zen-dark', 'relearn-bright', 'relearn-light', 'relearn-dark' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script><style type="text/css">

 
.center {
    align-content: center;
    text-align: center;
    margin: auto;
}
.alert {
    color: #ff3333;
}
.bsp {
    padding: 0.05cm;
    border-width: 0.05cm;
    border-style: solid;
    border-color: #ddd;
    background-color: #ddd;
    border-radius: 25px;
    float: right;
}
.cbox {
    padding: 0.2cm;
    border-width: 0.1cm;
    border-style: solid;
    border-color: #4070a0;
    background-color: #f2f2f2;
    margin: auto;
    width: 60%;
    text-align: center;
    overflow: auto;
}
.blueArrow {
    color: #4070a0;
    font-family: "Courier New", "Courier", monospace;
    font-weight: bold;
}
.origin {
    background-color: #ededed;
    font-size: 0.8em;
}
.showme {
    background-color: #ededed;
    font-size: 0.8em;
}


 
.tldr {
    background: #dbe4ed;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.recap {
    
    
   margin: 4px 0px 26px 0px;
}
.bib {
    background: #dbe4ed;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.outcomes {
    background: #d9e9d5;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.quizzes {
    background: #d9e9d5;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.challenges {
    background: #ebe4d6;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.assignments {
    background: #ebe4d6;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
h1.tldr, h1.recap, h1.bib, h1.outcomes, h1.quizzes, h1.challenges, h1.assignments {
    padding: 0px;
}


 
.noJsAlert {
    padding: 20px;
    background-color: #f44336;  
    color: white;
    margin-bottom: 15px;
}


 
.embed-video-player {
    position: relative;
    padding-bottom: 56%;
    height: 0;
    overflow: hidden;
}
.youtube-player {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border:0;
}


 
#header-wrapper {
    padding:0.6rem;
}


 
#shortcuts {
    padding-top: 2.0rem;
}


 
#chapter p {
    text-align: left;
}


 
figcaption h4 {
    margin-top:-2.5rem;
}
.border1 {
    border:1px solid black;
}

 
td ul, td ol {
    margin: 0 0 1rem 0.5rem;
    padding: 0 0 0 0.5rem;
}

 
h1 { font-size:2.8rem !important;}
h2 { font-size:2.2rem; margin:1.2rem 0}
h3 { font-size:1.9rem; text-align:left !important; font-weight:400 !important;}
h4 { font-size:1.6rem}
h5 { font-size:1.3rem}
h6 { font-size:1rem}

h2 {
    width:100% !important;
    border-bottom:1px solid #5e5e5e !important;
    padding-bottom: 2px;
}
.tldr h2, .recap h2, .bib h2, .outcomes h2, .quizzes h2, .challenges h2, .assignments h2 {
    margin:0.5rem 0
}

.btn-crossreference, .btn-crossreference:hover {
    cursor: initial;
}

</style>

  </head>
  <body class="mobile-support print disableInlineCopyToClipboard" data-url="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
          </div>
          <span class="topbar-breadcrumbs highlightable">
            Praktikum/Übung
          </span>
          <div class="topbar-area topbar-area-end" data-area="end">
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <article class="default">
            <header class="headline">
            </header>

<h1 id="praktikumübung">Praktikum/Übung</h1>

<p>Hier finden Sie die Übungsblätter.</p>
<p>Bitte bearbeiten Sie vor der jeweiligen Sprechstunde das bereitgestellte Material
(Skripte, Videos, Quizzes, Literatur, ...) und versuchen Sie vor der Sprechstunde
das entsprechende Übungsblatt zu lösen, damit Sie in der der Sprechstunde Ihre
Fragen zum Thema stellen können.</p>
<ul class="children children-li children-sort-">
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-perceptron.html">Übungsblatt: Perzeptron</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-regression.html">Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-mlp.html">Übungsblatt: Overfitting &amp; MLP</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-backprop.html">Übungsblatt: Backpropagation</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-dtl.html">Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL)</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-search.html">Übungsblatt: Problemlösen, Suche</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-ea.html">Übungsblatt: Lokale Suche, GA</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-games.html">Übungsblatt: Spiele</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-csp.html">Übungsblatt: Constraints</a></li>
  <li><a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nb.html">Übungsblatt: Naive Bayes</a></li>
</ul>

            <footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

            </footer>
          </article>

          <section>
            <h1 class="a11y-only">Subsections of Praktikum/Übung</h1>
<article class="default">
<h1>Übungsblatt: Perzeptron</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="bonus-möglichkeiten-und-grenzen-sowie-auswirkungen-der-ki-2p">Bonus: Möglichkeiten und Grenzen sowie Auswirkungen der KI (2P)</h2>
<p>Recherchieren Sie, welche Probleme bereits mittels Computer- bzw. Robotereinsatz
gelöst werden können und welche aktuell noch ungelöst sind.</p>
<p>Recherchieren Sie Auswirkungen auf die Gesellschaft durch die KI, etwa
durch autonomes Fahren oder durch <em>Large Language Models</em> (LLM).</p>
<p><em>Thema</em>: Gefühl für bereits realisierbare Aufgaben, Chancen und Risiken, Ethik</p>
<h2 id="nnperzeptron01-entscheidungsgrenze-2p">NN.Perzeptron.01: Entscheidungsgrenze (2P)</h2>
<ul>
<li>(1P) Betrachten Sie das durch den Gewichtsvektor <span class="math align-center">$(w_0,w_1,w_2)^T = (2,1,1)^T$</span> gegebene Perzeptron. Zeichnen Sie die Trennebene und markieren Sie den Bereich, der mit <span class="math align-center">$+1$</span> klassifiziert wird.</li>
<li>(1P) Welche der folgenden Perzeptrons haben die selbe Trennebene? Welche weisen exakt die gleiche Klassifikation auf?
<ul>
<li><span class="math align-center">$(w_0,w_1,w_2)^T = (1, 0.5, 0.5)^T$</span></li>
<li><span class="math align-center">$(w_0,w_1,w_2)^T = (200, 100, 100)^T$</span></li>
<li><span class="math align-center">$(w_0,w_1,w_2)^T = (\sqrt{2}, \sqrt{1}, \sqrt{1})^T$</span></li>
<li><span class="math align-center">$(w_0,w_1,w_2)^T = (-2, -1, -1)^T$</span></li>
</ul>
</li>
</ul>
<p><em>Thema</em>: Verständnis Interpretation Perzeptron (Trennebene/Entscheidungsgrenze)</p>
<h2 id="nnperzeptron02-logische-funktionen-als-perzeptron-2p">NN.Perzeptron.02: Logische Funktionen als Perzeptron (2P)</h2>
<ul>
<li>(1.5P) Das Perzeptron kann zur Ausführung zahlreicher logischer Funktionen verwendet werden. Implementieren Sie die binären Logikfunktionen UND, ODER und KOMPLEMENT und demonstrieren Sie Ihre Implementierung in der Übung/im Praktikum.</li>
<li>(0.5P) Eine grundlegende Einschränkung des Perzeptrons besteht darin, dass es die EXKLUSIV-ODER-Funktion nicht implementieren kann. Erklären Sie den Grund für diese Einschränkung.</li>
</ul>
<p><em>Thema</em>: Verständnis Perzeptron</p>
<h2 id="nnperzeptron03-perzeptron-lernalgorithmus-6p">NN.Perzeptron.03: Perzeptron Lernalgorithmus (6P)</h2>
<p>Ziel dieser Aufgabe ist es, mit Hilfe eines Experiments ein Gefühl für die Laufzeit des Perzeptron-Lernalgorithmus zu bekommen und eine Art empirische Approximation zu bestimmen.</p>
<h3 id="datensatz-1p">Datensatz (1P)</h3>
<ul>
<li>Konstruieren Sie Ihren eigenen Datensatz <span class="math align-center">$\mathcal{D}$</span> mit <span class="math align-center">$m=10$</span> gleichförmig verteilten Zufallspunkten aus dem Bereich <span class="math align-center">$\mathcal{X}=[−1, 1]\times[−1, 1]$</span>.</li>
<li>Wählen Sie auf ähnliche Weise zwei zufällige, gleichmäßig verteilte Punkte aus dem Bereich <span class="math align-center">$[−1, 1]\times[−1, 1]$</span>. Verwenden Sie die Gerade, die durch diese zwei Punkte verläuft, als die Entscheidungsgrenze Ihrer Zielfunktion <span class="math align-center">$f$</span>. Sie können die positiv beschriftete Seite beliebig festlegen.</li>
<li>Werten Sie die Zielfunktion für jeden Datenpunkt <span class="math align-center">$\mathbf{x}^{(j)}$</span> aus, um die entsprechenden Beschriftungen (Ausgangslabel) <span class="math align-center">$y^{(j)}$</span> zu erhalten.</li>
</ul>
<h3 id="training-3p">Training (3P)</h3>
<p>Führen Sie nun den Perzeptron-Lernalgorithmus <span class="math align-center">$1000$</span> mal hintereinander aus. Initialisieren Sie jedes Mal die Gewichte mit <span class="math align-center">$0$</span>. Wählen Sie in jedem Lernschritt einen Punkt <span class="math align-center">$\mathbf{x}^{(i)}$</span> <em>zufällig</em> aus der Menge der falsch klassifizierten Punkte und aktualisieren Sie die Gewichte entsprechend der folgenden Formel:
<span class="math align-center">$$\mathbf{w}:=\mathbf{w}+\alpha ( y^{(i)} - h(\mathbf{x}^{(i)}) ) \mathbf{x}^{(i)}$$</span></p>
<p>Nehmen Sie <span class="math align-center">$\alpha=1$</span> als Lernrate. Halten Sie für jeden Durchlauf fest, wie viele Schritte der Algorithmus benötigt, um zu der endgültigen Hypothese <span class="math align-center">$h^{*}(\mathbf{x})$</span> zu konvergieren. Berechnen Sie am Ende die durchschnittliche Anzahl von benötigten Schritten. In welcher Größenordnung liegt sie?</p>
<h3 id="experimente-2p">Experimente (2P)</h3>
<p>Wiederholen Sie das obige Experiment mit <span class="math align-center">$m=100$</span> und <span class="math align-center">$m=1000$</span> Datenpunkten, jeweils ein Mal mit den Lernraten <span class="math align-center">$\alpha=1$</span> und <span class="math align-center">$\alpha=0.1$</span>. In welcher Größenordnung liegt die durchschnittliche Anzahl von benötigten Schritten in diesen Fällen?</p>
<p>Um eine zuverlässigere Schätzung zu erhalten, können Sie dasselbe Experiment mehrfach mit anderen zufällig generierten Datensätzen derselben Größe <span class="math align-center">$m$</span> wiederholen und danach den Durchschnitt über alle Wiederholungen betrachten.</p>
<h3 id="visualisierung-optional">Visualisierung (optional)</h3>
<ul>
<li>Halten Sie während des Trainings die Anzahl der falsch klassifizierten Punkte fest und veranschaulichen Sie anschließend den Lernprozess mit Hilfe eines zweidimensionalen Plots.</li>
<li>Visualisieren Sie (auf eine geeignete Weise) Meilenstein 2.1, wie sich die Entscheidungsrenze während des Trainings verändert.</li>
</ul>
<p>Sie können das folgende <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/homework/files/perzeptron_lernalgorithmus_starter.ipynb" rel="external" target="_blank"><strong>Jupyter Notebook</strong></a> als Startpunkt benutzen.</p>
<p><em>Idee nach</em> Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin. 2012. Learning From Data. AMLBook.</p>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Lineare / Logistische Regression &amp; Gradientenabstieg</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="nnregression01-lineare-regression--gradientenabstieg-3p">NN.Regression.01: Lineare Regression &amp; Gradientenabstieg (3P)</h2>
<p>Es sind folgende Trainingsdaten gegeben:</p>
<span class="math align-center">$$ ( x^{(1)}, y^{(1)} ) = (1, 1), ( x^{(2)}, y^{(2)} ) = (2, 1), ( x^{(3)}, y^{(3)} ) = (3, 2) $$</span>
<p>Es soll das lineare Regressionsmodell <span class="math align-center">$h(x) = w_0 + w_1 x$</span> mit diesen Daten trainiert werden, wobei die zu minimierende Kostenfunktion (durchschnittliche Summe der Fehlerquadrate) wie folgt gegeben ist:</p>
<span class="math align-center">$$ J(\mathbf{w}) = \frac{1}{2m} \sum^{m}_{j=1} (h(x^{(j)}) - y^{(j)} )^2 $$</span>
<ul>
<li>
<p>(1P) Geben Sie <span class="math align-center">$n$</span> und <span class="math align-center">$m$</span> an und schreiben Sie die Kostenfunktion für die gegebenen Datenpunkte explizit auf. Berechnen Sie den Gradientenvektor <span class="math align-center">$\nabla J$</span> und beschreiben Sie die Bedeutung dieses Vektors.</p>
</li>
<li>
<p>(2P) Seien die Gewichte in einem Iterationsschritt <span class="math align-center">$w_0 = 1, w_1 = 1$</span>. Führen Sie für die Lernraten <span class="math align-center">$\alpha=0.01$</span>, <span class="math align-center">$\alpha=0.1$</span> und <span class="math align-center">$\alpha=1$</span> jeweils fünf aufeinanderfolgende Iterationen des Gradientenabstieg (Gradient Descent) Algorithmus durch.</p>
<p>Erstellen Sie eine Tabelle mit den Spalten <span class="math align-center">$w_0$</span>, <span class="math align-center">$w_1$</span>, <span class="math align-center">$J(\mathbf{w})$</span>, <span class="math align-center">$\nabla J(\mathbf{w})$</span>, <span class="math align-center">$\alpha \cdot \nabla J(\mathbf{w})$</span> und notieren Sie die zugehörigen Werte für jede Iteration. Erklären Sie, wie die Gewichtsaktualisierungen durchgeführt werden und geben Sie die dafür verwendete Formel an.</p>
<p>Wie verändern sich die Kosten während des Gradientenabstieges für die unterschiedlichen Lernraten? Begründen Sie dieses Verhalten.</p>
<p>Sie können das folgende <a href="https://www.geogebra.org/classic/rcfffgsj" rel="external" target="_blank"><strong>Geogebra-Arbeitsblatt</strong></a> zu Hilfe nehmen.</p>
</li>
</ul>
<p><em>Thema</em>: Verständnis und Ablauf Gradientenabstieg und Lernrate</p>
<h2 id="nnregression02-logistische-regression--gradientenabstieg-7p">NN.Regression.02: Logistische Regression &amp; Gradientenabstieg (7P)</h2>
<h3 id="datensatz-1p">Datensatz (1P)</h3>
<ul>
<li>Konstruieren Sie Ihren eigenen Datensatz <span class="math align-center">$\mathcal{D}$</span> mit <span class="math align-center">$m=100$</span> gleichförmig verteilten Zufallspunkten aus dem Bereich <span class="math align-center">$\mathcal{X}=[−1, 1]\times[−1, 1]$</span>.</li>
<li>Wählen Sie auf ähnliche Weise zwei zufällige, gleichmäßig verteilte Punkte aus dem Bereich <span class="math align-center">$[−1, 1]\times[−1, 1]$</span>. Verwenden Sie die Gerade, die durch diese zwei Punkte verläuft, als die Entscheidungsgrenze Ihrer Zielfunktion <span class="math align-center">$f$</span>. Sie können die positiv beschriftete Seite beliebig festlegen.</li>
<li>Werten Sie die Zielfunktion für jeden Datenpunkt <span class="math align-center">$\mathbf{x}^{(j)}$</span> aus, um die entsprechenden Beschriftungen (Ausgangslabel) <span class="math align-center">$y^{(j)}$</span> zu erhalten.</li>
</ul>
<h3 id="training-3p">Training (3P)</h3>
<p>Trainieren Sie ein logistisches Regressionsmodell auf diesen Daten, um
<span class="math align-center">$h^{*}=\sigma(w^T x)$</span> zu finden. Verwenden Sie dazu den Gradientenabstieg-Algorithmus. Initialisieren Sie alle Gewichtswerte mit 0 und führen Sie 2000 Iterationen durch. Nehmen Sie <span class="math align-center">$\alpha=0.1$</span> als Lernrate. Speichern Sie alle 100 Schritte die berechneten Kosten. Zeichnen Sie am Ende die Kosten als Diagramm über die Anzahl der Iterationen auf.</p>
<h3 id="experimente-3p">Experimente (3P)</h3>
<p>Wiederholen Sie das obige Experiment mit unterschiedlichen Lernraten, z.B. <span class="math align-center">$\alpha=0.1$</span>, <span class="math align-center">$\alpha=0.01$</span> und <span class="math align-center">$\alpha=0.001$</span>. Vergleichen Sie die Kosten-Diagramme.</p>
<p>Sie können das folgende <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/homework/files/logistische_regression_starter.ipynb" rel="external" target="_blank"><strong>Jupyter Notebook</strong></a> als Startpunkt benutzen. Sie können alternativ auch eine andere Programmiersprache und/oder einen anderen Datensatz (z.B. zufällig generierter Datensatz mittels Numpy and Scikit-Learn) verwenden.</p>
<p><em>Thema</em>: Verständnis und Implementierung Logistische Regression</p>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Overfitting &amp; MLP</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="nnmlp01-perzeptron-netze-2p">NN.MLP.01: Perzeptron-Netze (2P)</h2>
<p>Konstruieren Sie ein Netz mit drei Perzeptrons, welches für zwei Eingabevariablen <span class="math align-center">$x_1$</span> und <span class="math align-center">$x_2$</span> die in der folgenden Abbildung blau-grau dargestellten Bereiche mit +1 klassifiziert. Benutzen Sie die <span class="math align-center">$\operatorname{sign}$</span>-Funktion als Aktivierungsfunktion.</p>
<figure class="center">
    <img src="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-mlp/perzeptron_netz.png" alt="Abbildung 1" width="60%" height="auto">
    <figcaption><p>Abbildung 1</p></figcaption>
</figure>
<h2 id="nnmlp02-vorwärtslauf-im-mlp-2p">NN.MLP.02: Vorwärtslauf im MLP (2P)</h2>
<p>Gegeben sei ein MLP mit 25 Zellen in der Eingangsschicht, 64 Zellen in der ersten versteckten Schicht, 32 Zellen in der zweiten versteckten Schicht und 4 Zellen in der Ausgabeschicht (die Bias-Zellen nicht mitgezählt). In allen Zellen wird die ReLU Aktivierungsfunktion verwendet.</p>
<ul>
<li>Was sind die Dimensionen der Gewichtsmatrizen <span class="math align-center">$W^{[1]}$</span>, <span class="math align-center">$W^{[2]}$</span> und <span class="math align-center">$W^{[3]}$</span> und der Bias-Vektoren <span class="math align-center">$b^{[1]}$</span>, <span class="math align-center">$b^{[2]}$</span> und <span class="math align-center">$b^{[3]}$</span>?</li>
<li>Wie wird die Ausgabe berechnet? Schreiben Sie den Vorwärtslauf in Matrix-Notation auf. Wie könnte man die Ausgabe deuten; welches Problem könnte durch dieses Netzwerk möglicherweise gelöst werden?</li>
</ul>
<h2 id="nnmlp03-tensorflow-playground-6p">NN.MLP.03: Tensorflow Playground (6P)</h2>
<p>Benutzen Sie den <a href="https://playground.tensorflow.org/" rel="external" target="_blank">Neural Network Playground</a>, um die unten gelisteten Experimente durchzuführen. Achten Sie bei allen Experimenten auf das Verhalten der Trainings- und Testkosten. Sie können mit Hilfe der Checkbox unter der Ausgabezelle (ganz rechts, unten) die Testdaten ein- und ausblenden. Der Play-Knopf startet dabei das Training und der Reload-Knopf setzt das Netzwerk zurück.</p>
<ol>
<li>
<p>(1P) Trainieren Sie ein <strong>logistisches Regressionsmodell</strong> zunächst auf dem &quot;<strong>Gaussian</strong>&quot; Datensatz (linear separierbarer Datensatz links-unten), danach auf den anderen Datensätzen.</p>
</li>
<li>
<p>(3P) Trainieren Sie ein <strong>MLP</strong> mit</p>
<ul>
<li>einer versteckten Schicht mit 2 Neuronen,</li>
<li>einer versteckten Schicht mit 3 Neuronen,</li>
<li>einer versteckten Schicht mit 5 Neuronen,</li>
<li>zwei versteckten Schichten mit jeweils 5 Neuronen pro Schicht</li>
<li>drei versteckten Schichten mit jeweils 7 Neuronen pro Schicht</li>
<li>vier versteckten Schichten mit jeweils 7 Neuronen pro Schicht</li>
</ul>
<p>auf dem kreisförmigen (<strong>Circle</strong>) und auf dem spiralförmigen (<strong>Spiral</strong>) Datensatz, mehrmals mit jeweils den Aktivierungsfunktionen ReLU, tanh und Sigmoid. Hat die Auswahl der Aktivierungsfunktion einen Einfluss auf die Form der Entscheidungsgrenze oder die Geschwindigkeit der Berechnung?</p>
</li>
<li>
<p>(2P) Setzen Sie nun den <strong>Noise-Level auf 15</strong> und wiederholen Sie die Experimente. Wann kann von einer Überanpassung gesprochen werden?</p>
</li>
</ol>
<p>Sprechen Sie für alle Experimente die folgenden Punkte an:</p>
<ul>
<li>Wie verhält sich die Entscheidungsgrenze?</li>
<li>Was können Sie über Trainings- und Testkosten sagen? Entsteht eine Überanpassung?</li>
<li>Wie schnell wird die Entscheidungsgrenze berechnet?</li>
<li>Können alle Datenpunkte jedes mal korrekt klassifiziert werden? Warum?</li>
<li>Untersuchen und vergleichen Sie die Ausgaben der Zellen in den versteckten Schichten, in dem Sie die Maus über die jeweilige Zelle bewegen. Bemerken Sie einen wesentlichen Unterschied in den Ausgaben der ersten Schicht im Vergleich zu der letzten Schicht?</li>
</ul>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Backpropagation</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="nnbackprop01-gewichtsupdates-für-versteckte-schichten-2p">NN.Backprop.01: Gewichtsupdates für versteckte Schichten (2P)</h2>
<p>In der Vorlesung wurde(n) die Gewichtsupdates bei der Backpropagation für die Ausgabeschicht und die davor liegende letzte versteckte Schicht hergeleitet, wobei in der Ausgabeschicht die Sigmoid und in der versteckten Schicht die ReLU Aktivierungsfunktionen eingesetzt wurden.
Leiten Sie die Gewichtsupdates für die erste versteckte Schicht (für ein Netz mit zwei echten versteckten Schichten) her. Verwenden Sie dabei die Sigmoid Funktion als Aktivierung in allen Schichten.</p>
<p><em>Thema</em>: Verständnis Backpropagation</p>
<h2 id="nnbackprop02-forward--und-backpropagation-2p">NN.Backprop.02: Forward- und Backpropagation (2P)</h2>
<p>Betrachten Sie das folgende MLP mit zwei Schichten mit insgesamt zwei Zellen. Die Gewichte sind an den Kanten angegeben. Das Netz erhält den skalaren Input <span class="math align-center">$x$</span> und berechnet daraus die Ausgabe <span class="math align-center">$y$</span>. Beide Zellen verwenden die Aktivierungsfunktion
<span class="math align-center">$\sigma(z) = \frac{1}{ 1 + e^{−z} }$</span>.</p>
<figure class="center">
    <img src="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-backprop/mlp.png" alt="Abbildung 1" width="50%" height="auto">
    <figcaption><p>Abbildung 1</p></figcaption>
</figure>
<ul>
<li>
<p>(1P) Berechnen Sie die Ausgabe <span class="math align-center">$y$</span> für die Eingabe <span class="math align-center">$(x,y_T)=(0, 0.5)$</span>. Wie groß ist der Fehler?</p>
</li>
<li>
<p>(1P) Berechnen Sie die partiellen Ableitungen für die Gewichte. Wie lauten die Gewichtsupdates für das obige Trainingsbeispiel? Setzen Sie <span class="math align-center">$\alpha = 0.01$</span>.</p>
</li>
</ul>
<h2 id="nnbackprop03-mlp-und-backpropagation-6p">NN.Backprop.03: MLP und Backpropagation (6P)</h2>
<p>Implementieren Sie ein Feedforward MLP mit mindestens einer versteckten Schicht. Nutzen Sie die Cross-Entropy Verlustfunktion.</p>
<ul>
<li>
<p>(2P) Implementieren Sie die Forwärtspropagation. Nutzen Sie als Aktivierungsfunktion in der Ausgangsschicht <span class="math align-center">$g(z) = \frac{1}{ 1 + e^{−z} }$</span> und in der versteckten Schicht <span class="math align-center">$g(z) = ReLU(z)$</span>.</p>
</li>
<li>
<p>(2P) Implementieren Sie das Backpropagations-Verfahren zum Aktualisieren der Gewichte. Achten Sie insbesondere darauf, die bereits berechneten partiellen Ableitungen der jeweils hinteren Schicht wieder zu verwenden (und nicht jeweils erneut zu berechnen!), d.h. propagieren Sie die Fehler von hinten nach vorn durch das Netz.</p>
</li>
<li>
<p>(2P) Trainieren Sie das Netz für den Iris-Datensatz (iris.csv) aus dem <a href="https://github.com/aimacode/aima-data" rel="external" target="_blank">AIMA-Repository</a> und nutzen Sie dabei die Variante des stochastischen Gradientenabstiegs. Messen Sie pro Epoche (also nach jedem Durchlauf durch den kompletten Datensatz) den Trainingsfehler. Zeichnen Sie den Trainingsfehler als Diagramm über den Epochen auf.</p>
</li>
</ul>
<p>Falls der Trainingsfehler nach einigen tausend Epochen nicht gegen einen Wert nahe Null strebt, erweitern Sie Ihr Netz (beispielsweise eine versteckte Schicht mehr oder mehr Zellen in der schon existierenden versteckten Schicht, ...) und trainieren Sie es erneut. Nach wievielen Epochen ist der Trainingsfehler fast Null?</p>
<p><em>Thema</em>: Verständnis MLP und Backpropagation, Gefühl für nötige Größe des Netzes</p>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Entscheidungsbäume (Decision Tree Learner DTL)</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="dtl01-entscheidungsbäume-mit-cal3-und-id3-6p">DTL.01: Entscheidungsbäume mit CAL3 und ID3 (6P)</h2>
<p>Es ist wieder Wahlkampf: Zwei Kandidaten O und M bewerben sich um die Kanzlerschaft. Die
folgende Tabelle zeigt die Präferenzen von sieben Wählern.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Nr.</th>
          <th style="text-align: left">Alter</th>
          <th style="text-align: left">Einkommen</th>
          <th style="text-align: left">Bildung</th>
          <th style="text-align: left">Kandidat</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left"><span class="math align-center">$\ge 35$</span></td>
          <td style="text-align: left">hoch</td>
          <td style="text-align: left">Abitur</td>
          <td style="text-align: left">O</td>
      </tr>
      <tr>
          <td style="text-align: left">2</td>
          <td style="text-align: left"><span class="math align-center">$< 35$</span></td>
          <td style="text-align: left">niedrig</td>
          <td style="text-align: left">Master</td>
          <td style="text-align: left">O</td>
      </tr>
      <tr>
          <td style="text-align: left">3</td>
          <td style="text-align: left"><span class="math align-center">$\ge 35$</span></td>
          <td style="text-align: left">hoch</td>
          <td style="text-align: left">Bachelor</td>
          <td style="text-align: left">M</td>
      </tr>
      <tr>
          <td style="text-align: left">4</td>
          <td style="text-align: left"><span class="math align-center">$\ge 35$</span></td>
          <td style="text-align: left">niedrig</td>
          <td style="text-align: left">Abitur</td>
          <td style="text-align: left">M</td>
      </tr>
      <tr>
          <td style="text-align: left">5</td>
          <td style="text-align: left"><span class="math align-center">$\ge 35$</span></td>
          <td style="text-align: left">hoch</td>
          <td style="text-align: left">Master</td>
          <td style="text-align: left">O</td>
      </tr>
      <tr>
          <td style="text-align: left">6</td>
          <td style="text-align: left"><span class="math align-center">$< 35$</span></td>
          <td style="text-align: left">hoch</td>
          <td style="text-align: left">Bachelor</td>
          <td style="text-align: left">O</td>
      </tr>
      <tr>
          <td style="text-align: left">7</td>
          <td style="text-align: left"><span class="math align-center">$< 35$</span></td>
          <td style="text-align: left">niedrig</td>
          <td style="text-align: left">Abitur</td>
          <td style="text-align: left">M</td>
      </tr>
  </tbody>
</table>
<p>Trainieren Sie nacheinander mit den Verfahren CAL3 (3P) und ID3 (3P) auf der obigen
Trainingsmenge je einen Entscheidungsbaum. Nutzen Sie für CAL3 dabei die Schwellen <span class="math align-center">$S_1=4$</span> und
<span class="math align-center">$S_2=0.7$</span>.</p>
<p>Sie können dafür eine Handsimulation anwenden oder die Algorithmen implementieren. Sie können
gern auch die Java-Klassen im Paket <a href="https://github.com/aimacode/aima-java/blob/AIMA3e/aima-core/src/main/java/aima/core/learning/learners/DecisionTreeLearner.java" rel="external" target="_blank"><code>aima.core.learning</code></a> bzw. die Python-Klassen in
<a href="https://github.com/aimacode/aima-python/blob/master/learning.py" rel="external" target="_blank"><code>learning.py</code></a> als Ausgangspunkt nutzen.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<h2 id="dtl02-pruning-1p">DTL.02: Pruning (1P)</h2>
<p>Vereinfachen Sie schrittweise den Baum</p>
<span class="math align-center">$$x_3(x_2(x_1(C,A), x_1(B,A)), x_1(x_2(C,B), A))$$</span>
<p>so weit wie möglich.</p>
<p>Nutzen Sie die linearisierte Schreibweise. Geben Sie die jeweils verwendete Regel an.</p>
<p><em>Thema</em>: Anwendung der Transformations- und Pruning-Regeln</p>
<h2 id="dtl03-machine-learning-mit-weka-3p">DTL.03: Machine Learning mit Weka (3P)</h2>
<p>Weka (<a href="https://waikato.github.io/weka-wiki/" rel="external" target="_blank">waikato.github.io/weka-wiki/</a>) ist eine beliebte Sammlung von (in Java implementierten)
Algorithmen aus dem Bereich des Maschinellen Lernens. Laden Sie sich das Tool in der aktuellen
stabilen Version herunter und machen Sie sich mit der beiliegenden Dokumentation vertraut.</p>
<p>Laden Sie sich die Beispieldatensätze &quot;Zoo&quot; (<code>zoo.csv</code>) und &quot;Restaurant&quot; (<code>restaurant.csv</code>)
aus dem AIMA-Repository (<a href="https://github.com/aimacode/aima-data" rel="external" target="_blank">github.com/aimacode/aima-data</a>) herunter.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Zum Laden der
Beispieldatensätze in Weka müssen die <code>.csv</code>-Dateien eine Kopfzeile mit den Namen der
Attribute haben. Passen Sie die Dateien entsprechend an und laden Sie diese im Reiter
&quot;Pre-Process&quot; mit &quot;Open file ...&quot;.</p>
<p><em>Hinweis</em>: Wenn Sie <em>Weka 3.6</em> einsetzen, sind alle für dieses Blatt erforderlichen
Algorithmen bereits vorhanden. In neueren Versionen müssen Sie in der Weka-Haupt-GUI den
Paketmanager unter &quot;Tools&quot; starten und dort nach einem Paket suchen, welches ID3 enthält, und
dieses Paket nachinstallieren.</p>
<ol>
<li>
<p>Training mit J48 (1P)</p>
<p>Wechseln Sie auf den Reiter &quot;Classify&quot; und wählen Sie mit dem Button &quot;Choose&quot; den
Entscheidungsbaum-Lerner J48 aus. (Dies ist eine Java-Implementierung von C4.5. Die
ID3-Implementierung funktioniert für den <code>zoo.csv</code>-Datensatz leider nicht ...)</p>
<p>Lernen Sie für die beiden Datensätze je einen Entscheidungsbaum. Wie sehen die Bäume aus?
Wie hoch ist jeweils die Fehlerrate für den Trainingssatz? (Stellen Sie unter &quot;Test
options&quot; den Haken auf &quot;Use training set&quot;.) Interpretieren Sie die <strong>Confusion Matrix</strong>.</p>
</li>
<li>
<p>ARFF-Format (1P)</p>
<p>Lesen Sie in der beiliegenden Doku zum Thema &quot;ARFF&quot; nach. Dabei handelt es sich um ein
spezielles Datenformat, womit man Weka mitteilen kann, welche Attribute es gibt und
welchen Typ diese haben und welche Werte auftreten dürfen. (<a href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/" rel="external" target="_blank">Link</a>)</p>
<p>Erklären Sie die Unterschiede zwischen &quot;nominal&quot;, &quot;ordinal&quot; (bzw. &quot;numeric&quot;) und &quot;string&quot;.</p>
<p>Konvertieren Sie den Zoo- und Restaurantdatensatz in das ARFF-Format. Beachten Sie, dass
die ID3-Implementierung von Weka nicht mit bestimmten Attributtypen umgehen kann.</p>
</li>
<li>
<p>Training mit ID3 und J48 (1P)</p>
<p>Trainieren Sie für die im letzten Schritt erstellten Datensätze (Zoo und Restaurant) im
ARFF-Format erneut Entscheidungsbäume. Nutzen Sie diesmal sowohl ID3 als auch J48.</p>
<p>Vergleichen Sie wieder die Ergebnisse (Entscheidungsbäume, Fehlerraten, Confusion Matrix)
untereinander und mit den Ergebnissen aus dem J48-Lauf mit den <code>.csv</code>-Dateien.</p>
</li>
</ol>
<p><em>Thema</em>: Kennenlernen von Weka</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Im Python-Code tauchen immer wieder &quot;TODO&quot;-Marker auf - bitte mit Vorsicht genießen!&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Zum Zoo-Datensatz gibt es die Erklärung direkt im Repo, für den Restaurant-Datensatz
finden Sie die Erklärung im AIMA (Buch).&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Problemlösen, Suche</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="search01-problemformalisierung-zustandsraum-3p">Search.01: Problemformalisierung, Zustandsraum (3P)</h2>
<p>Drei Elben und drei Orks befinden sich an einem Ufer eines Flusses und wollen diesen
überqueren. Es steht dazu ein Pferd zur Verfügung, welches maximal zwei Wesen tragen kann. Das
Pferd kann den Fluss nicht allein überqueren.</p>
<p>Gesucht ist eine Möglichkeit, alle Elben und Orks über den Fluss zu bringen. Dabei darf zu
keiner Zeit an keinem Ufer die Anzahl der sich dort befindlichen Orks größer sein als die der
dort wartenden Elben, da es sonst zu Konflikten zwischen beiden Gruppen kommt.</p>
<ol>
<li>Formalisieren Sie das Problem (Zustände, Aktionen, Start- und Endzustand).</li>
<li>Skizzieren Sie den Problemgraph.</li>
</ol>
<p><em>Thema</em>: Formalisierung von Problemen, Problemgraph</p>
<h2 id="search02-suchverfahren-5p">Search.02: Suchverfahren (5P)</h2>
<p>Betrachten Sie folgende Landkarte und Restwegschätzungen:</p>
<p><a href="#R-image-ba05234c5a00b4b4c134afdc939404fa" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/MapGermanyGraph.svg/476px-MapGermanyGraph.svg.png?width=40%25&height=auto" style=" height: auto; width: 40%;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-ba05234c5a00b4b4c134afdc939404fa"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/MapGermanyGraph.svg/476px-MapGermanyGraph.svg.png?width=40%25&height=auto"></a></p>
<p><span class='origin'>Quelle: <a href="https://commons.wikimedia.org/wiki/File:MapGermanyGraph.svg" rel="external" target="_blank">MapGermanyGraph.svg</a> by <a href="https://de.wikipedia.org/wiki/Benutzer:Regnaron" rel="external" target="_blank">Regnaron</a> and <a href="https://commons.wikimedia.org/wiki/User:Jahobr" rel="external" target="_blank">Jahobr</a> on Wikimedia Commons (<a href="https://en.wikipedia.org/wiki/en:public_domain" rel="external" target="_blank">Public
Domain</a>)</span></p>
<p><a href="#R-image-5eef2753a09598c6fe4f5b7326bf66fd" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-search/MapGermanyGraph-Kosten.png?width=40%25&height=auto" style=" height: auto; width: 40%;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-5eef2753a09598c6fe4f5b7326bf66fd"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-search/MapGermanyGraph-Kosten.png?width=40%25&height=auto"></a></p>
<ol>
<li>
<p>Finden Sie nacheinander mit Tiefensuche (1P) und Breitensuche (1P) (jeweils in der
Graph-Search-Variante) sowie A* (2P) (in der Tree-Search-Variante mit der Verbesserung
&quot;keine Zyklen&quot;, siehe Vorlesung) jeweils einen Weg von Würzburg nach München.</p>
<p>Vergleichen Sie die drei Algorithmen: Wie viele Einträge gibt es in der Datenstruktur
maximal, wie oft wird die Hauptschleife durchlaufen (also ein Element aus der
Datenstruktur entnommen, untersucht und weiterentwickelt)?</p>
<p>Sie können dafür eine Handsimulation anwenden oder die Algorithmen implementieren. Sie
können gern auch die Java-Klassen im Paket <a href="https://github.com/aimacode/aima-java/tree/AIMA3e/aima-core/src/main/java/aima/core/search" rel="external" target="_blank"><code>aima.core.search</code></a> bzw. die Python-Klassen in
<a href="https://github.com/aimacode/aima-python/blob/master/search.py" rel="external" target="_blank"><code>search.py</code></a> als Ausgangspunkt nutzen.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
</li>
<li>
<p>Dürfen die oben gegebenen Restkostenabschätzungen in A* verwendet werden? (1P)</p>
<ul>
<li>Falls ja, warum?</li>
<li>Falls nein, warum? Wie müssten die Abschätzungen ggf. korrigiert werden?</li>
</ul>
<p>Falls Sie der Meinung waren, die Abschätzungen sind nicht korrekt, korrigieren Sie die
Abschätzungen nun und führen Sie erneut eine Suche mit A* durch.</p>
</li>
</ol>
<p><em>Hinweis</em>: Reihenfolge bei gleichen <span class="math align-center">$f(n)$</span>-Kosten: alphabetische Reihenfolge, d.h. Mannheim
käme vor München, Karlsruhe vor Kassel etc.</p>
<h2 id="search03-dominanz-1p">Search.03: Dominanz (1P)</h2>
<p>Was bedeutet <em>&quot;Eine Heuristik <span class="math align-center">$h_1(n)$</span> dominiert eine Heuristik <span class="math align-center">$h_2(n)$</span>&quot;</em>?</p>
<p>Wie wirkt sich die Nutzung einer dominierenden Heuristik <span class="math align-center">$h_1(n)$</span> in A* aus (im Vergleich zur
Nutzung einer Heuristik <span class="math align-center">$h_2$</span>, die von <span class="math align-center">$h_1$</span> dominiert wird)?</p>
<p>Geben Sie selbstgewählte Beispiele an.</p>
<p><em>Thema</em>: Begriff der dominierenden Heuristik (Selbststudium)</p>
<h2 id="search04-beweis-der-optimalität-von-a-1p">Search.04: Beweis der Optimalität von A* (1P)</h2>
<p>Beweisen Sie, dass A* in der Tree-Search-Variante bei Nutzung einer zulässigen Heuristik
optimal ist.</p>
<p><em>Thema</em>: Bedeutung einer zulässigen Heuristik (Selbststudium)</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Im Python-Code tauchen immer wieder &quot;TODO&quot;-Marker auf - bitte mit Vorsicht genießen!&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Lokale Suche, GA</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="ea01-modellierung-von-ga-2p">EA.01: Modellierung von GA (2P)</h2>
<p>Betrachten Sie das 8-Queens-Problem sowie das Landkarten-Färbeproblem (aus Vorlesung <a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/csp/csp1-intro.html">CSP: Intro</a>). Starten Sie beim Färbeproblem mit fünf verschiedenen Farben, Ziel sollte eine
konfliktfreie Einfärbung mit einer minimalen Anzahl an Farben sein.</p>
<p>Geben Sie für beide Probleme je eine geeignete <strong>Kodierung</strong> der Individuen, passende
Operatoren (<strong>Crossover</strong>, <strong>Mutation</strong>) und eine geeignete <strong>Fitnessfunktion</strong> an, damit die
Probleme mit einem GA gelöst werden können. Begründen Sie Ihre Wahl!</p>
<p>Was würden Sie noch benötigen, um die obigen Probleme jeweils mit Simulated Annealing lösen zu
können?</p>
<p><em>Thema</em>: Modellierung für GA und Gradientensuche</p>
<h2 id="ea02-implementierung-5p">EA.02: Implementierung (5P)</h2>
<p>Implementieren Sie den in der Vorlesung besprochenen GA und wenden Sie den Algorithmus
nacheinander auf beide Probleme an. Sie können gern auch die Java-Klassen im Paket
<a href="https://github.com/aimacode/aima-java/tree/AIMA3e/aima-core/src/main/java/aima/core/search/local" rel="external" target="_blank"><code>aima.core.search.local</code></a> bzw. die Python-Klassen in <a href="https://github.com/aimacode/aima-python/blob/master/search.py" rel="external" target="_blank"><code>search.py</code></a> als Ausgangspunkt
nutzen.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Untersuchen Sie <strong>systematisch</strong> unterschiedliche Varianten/Einstellungen der in der VL
vorgestellten Operatoren. Führen Sie pro Einstellung jeweils mind. 100 Läufe durch und messen
Sie die besprochenen Kennzahlen.</p>
<p>Erstellen Sie eine geeignete (systematische!) Auswertung Ihrer Experimente.</p>
<h2 id="ea03-anwendungen-3p">EA.03: Anwendungen (3P)</h2>
<ol>
<li>Analysieren Sie die Implementierung von <a href="http://www.randalolson.com/2015/02/03/heres-waldo-computing-the-optimal-search-strategy-for-finding-waldo/" rel="external" target="_blank">Randal Olson &quot;Here's Waldo: Computing the optimal
search strategy for finding Waldo&quot;</a> (<a href="https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects" rel="external" target="_blank">Direktlink</a>).</li>
<li>Schauen Sie sich nun den <a href="https://www.openprocessing.org/sketch/205807" rel="external" target="_blank">&quot;Evolution Simulator&quot;</a> an. Wie ist dort die Modellierung erfolgt
(Kodierung, Operatoren, Fitnessfunktion)?</li>
<li>Wie werden EA/GA konkret im <a href="https://lcamtuf.coredump.cx/afl/" rel="external" target="_blank">&quot;american fuzzy lop&quot;</a> eingesetzt?</li>
</ol>
<p>Welche Fitnessfunktion wurden in den drei Beispielen jeweils genutzt, wie die Individuen und
die Operatoren codiert?</p>
<p>Recherchieren Sie, in welchen <em>anderen</em> Anwendungen Evolutionäre Algorithmen eingesetzt
werden. Erklären Sie kurz, wie und wofür die EA/GA jeweils genutzt werden.</p>
<p><em>Thema</em>: Analyse von GA-Implementierungen</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Im Python-Code tauchen immer wieder &quot;TODO&quot;-Marker auf - bitte mit Vorsicht genießen!&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Spiele</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="games01-handsimulation-minimax-und-alpha-beta-pruning-3p">Games.01: Handsimulation: Minimax und alpha-beta-Pruning (3P)</h2>
<p><a href="#R-image-8594767e7360a27b325b6d4b2f431e29" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-games/alphabeta.png?width=auto&height=auto" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-8594767e7360a27b325b6d4b2f431e29"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-games/alphabeta.png?width=auto&height=auto"></a></p>
<ol>
<li>
<p>(1P) Geben Sie für den Spielbaum die Minimax-Bewertungen an.</p>
</li>
<li>
<p>(1P) Markieren Sie die Kanten, die bei alpha-beta-Pruning nicht mehr untersucht werden
würden, d.h. wo Pruning stattfinden würde. Geben Sie für jeden Knoten die (sich ändernden)
<span class="math align-center">$\alpha$</span>- und <span class="math align-center">$\beta$</span>-Werte an.</p>
</li>
<li>
<p>(1P) Können die Knoten derart geordnet werden, dass alpha-beta-Pruning eine größere Anzahl
von Zweigen abschneidet? Wenn ja, geben Sie eine solche Ordnung an. Wenn nein, begründen
Sie Ihre Antwort.</p>
</li>
</ol>
<p><em>Hinweis</em>: Reihenfolge der Abarbeitung der Kindknoten: Wie in der VL von links nach rechts.</p>
<p><em>Thema</em>: Minimax und alpha-beta-Pruning</p>
<h2 id="games02-optimale-spiele-minimax-und-alpha-beta-pruning-4p">Games.02: Optimale Spiele: Minimax und alpha-beta-Pruning (4P)</h2>
<ol>
<li>
<p>(2P) Implementieren Sie den Minimax-Algorithmus (wie in der VL besprochen) am Beispiel
<em>Tic Tac Toe</em> in einer Sprache Ihrer Wahl.</p>
</li>
<li>
<p>(1P) Ergänzen Sie Ihre Implementierung um alpha-beta-Pruning.</p>
</li>
<li>
<p>(1P) Vergleichen Sie die Anzahl der jeweils berechneten Knoten. Überlegen Sie sich dazu
ein <strong>sinnvolles</strong> Szenario.</p>
</li>
</ol>
<p><em>Thema</em>: Anwendung Minimax und alpha-beta-Pruning</p>
<h2 id="games03-minimax-vereinfachen-1p">Games.03: Minimax vereinfachen (1P)</h2>
<p>Vereinfachen Sie den Minimax-Algorithmus aus der Vorlesung, indem Sie die Eigenschaft
<em>Nullsummenspiel</em> berücksichtigen und die Funktionen <code>Min-Value</code> und <code>Max-Value</code> in eine
einzige Funktion ohne explizite Unterscheidung der Spieler zusammenfassen.</p>
<p>Überlegen Sie sich einen Beispielbaum und zeigen Sie anhand dessen die Bewertung durch den
Minimax-Algorithmus und durch Ihren vereinfachten Algorithmus.</p>
<p><em>Thema</em>: Nullsummenspiel, Minimax</p>
<h2 id="games04-suchtiefe-begrenzen-1p">Games.04: Suchtiefe begrenzen (1P)</h2>
<p>Die Verwendung der Suchtiefenbeschränkung erfordert den Einsatz einer Evaluierungsfunktion.</p>
<p>Betrachten Sie die auf
<a href="https://aimacode.github.io/aima-exercises/game-playing-exercises/ex_9/" rel="external" target="_blank">https://github.com/aimacode/aima-exercises/blob/master/markdown/5-Adversarial-Search/exercises/ex_9/question.md</a>
gegebene Evaluierungsfunktion für <em>Tic-Tac-Toe</em>.</p>
<p>Geben Sie die Werte der Evaluierungsfunktion für sechs verschiedene Spielzustände an (3
Endzustände, 3 Zwischenzustände). Begründen Sie, warum diese Evaluierungsfunktion im
Zusammenhang mit <em>Tic-Tac-Toe</em> sinnvoll sein kann.</p>
<p><em>Thema</em>: Suchtiefenbegrenzung und Evaluierungsfunktion</p>
<h2 id="games05-minimax-generalisiert-1p">Games.05: Minimax generalisiert (1P)</h2>
<p>Betrachten Sie nun das Problem, den Spielbaum eines Drei-Personen-Spiels zu evaluieren, das
nicht notwendigerweise die Nullsummenbedingung erfüllt.</p>
<p><a href="#R-image-92f555e3d1e9a02a695c7dec800c6599" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-games/minmax-multiplayer.png?width=auto&height=auto" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-92f555e3d1e9a02a695c7dec800c6599"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-games/minmax-multiplayer.png?width=auto&height=auto"></a></p>
<p>Die Spieler heißen 1, 2 und 3. Im Gegensatz zu Zwei-Personen-Nullsummenspielen liefert die
Bewertungsfunktion nun Tripel <span class="math align-center">$(x_1, x_2, x_3)$</span> zurück, wobei <span class="math align-center">$x_i$</span> der Wert für Spieler <span class="math align-center">$i$</span>
ist. Allianzen zwischen Spielern sind nicht erlaubt.</p>
<p>Vervollständigen Sie den Spielbaum, indem Sie alle inneren Knoten und den Wurzelknoten mit den
entsprechenden Wert-Tripeln annotieren.</p>
<p><em>Thema</em>: Minimax generalisiert für mehrere Spieler</p>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Constraints</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="csp01-logikrätsel-2p">CSP.01: Logikrätsel (2P)</h2>
<p>Betrachten Sie die Variante des berühmten <a href="https://de.wikipedia.org/wiki/Zebrar%C3%A4tsel" rel="external" target="_blank">&quot;Einstein-Rätsels&quot;</a> auf Wikipedia.</p>
<p>Formulieren Sie das Problem als CSP (Variablen, Wertebereiche, Constraints) zunächst auf dem
Papier. Machen Sie sich klar, was die Variablen und was deren Wertebereiche sind. Schreiben
Sie die Constraints als (unäre bzw. binäre) Relationen zwischen den Variablen auf.</p>
<p><em>Hinweis</em>: Machen Sie sich zunächst klar, was die Variablen und was deren Wertebereiche sind.
Schreiben Sie die Constraints als (unäre bzw. binäre) Relationen auf.</p>
<p><em>Thema</em>: Formulierung von Problemen als CSP</p>
<h2 id="csp02-framework-für-constraint-satisfaction-2p">CSP.02: Framework für Constraint Satisfaction (2P)</h2>
<p>Lösen Sie nun das obige Rätsel (aus CSP.01):</p>
<ol>
<li>Lösen Sie das Rätsel zunächst mit dem Basis-Algorithmus <code>BT_Search</code> aus der Vorlesung.</li>
<li>Erweitern Sie den Algorithmus um die Heuristiken MRV und Gradheuristik und lösen Sie das
Problem erneut. Vergleichen Sie die Ergebnisse und die Laufzeit der beiden Experimente.</li>
<li>Wenden Sie vor dem Start von <code>BT_Search</code> den AC-3 an. Erhalten Sie damit bereits eine
Lösung (bzw. Unlösbarkeit)? Falls nicht, wenden Sie anschließend den ergänzten Algorithmus
aus Schritt (2) an. Vergleichen Sie wieder die Ergebnisse und die Laufzeiten.</li>
</ol>
<p>Sie können dafür eine Handsimulation anwenden oder die Algorithmen implementieren. Sie können
gern auch die Java-Klassen im Paket <a href="https://github.com/aimacode/aima-java/tree/AIMA3e/aima-core/src/main/java/aima/core/search/csp" rel="external" target="_blank"><code>aima.core.search.csp</code></a> bzw. die Python-Klassen in
<a href="https://github.com/aimacode/aima-python/blob/master/csp.py" rel="external" target="_blank"><code>csp.py</code></a> als Ausgangspunkt nutzen.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<h2 id="csp03-kantenkonsistenz-mit-ac-3-3p">CSP.03: Kantenkonsistenz mit AC-3 (3P)</h2>
<p>Sei <span class="math align-center">$D=\lbrace 0, \ldots, 5 \rbrace$</span>, und ein Constraintproblem definiert durch</p>
<span class="math align-center">$$\langle
    \lbrace v_1, v_2, v_3, v_4 \rbrace,
    \lbrace D_{v_1} = D_{v_2} = D_{v_3} = D_{v_4} = D \rbrace,
    \lbrace c_1, c_2, c_3, c_4 \rbrace
\rangle$$</span>
<p>mit</p>
<ul>
<li><span class="math align-center">$c_1=\left((v_1,v_2), \lbrace (x,y) \in D^2 | x+y = 3 \rbrace\right)$</span>,</li>
<li><span class="math align-center">$c_2=\left((v_2,v_3), \lbrace (x,y) \in D^2 | x+y \le 3 \rbrace\right)$</span>,</li>
<li><span class="math align-center">$c_3=\left((v_1,v_3), \lbrace (x,y) \in D^2 | x \le y \rbrace\right)$</span> und</li>
<li><span class="math align-center">$c_4=\left((v_3,v_4), \lbrace (x,y) \in D^2 | x \ne y \rbrace\right)$</span>.</li>
</ul>
<ol>
<li>(1P) Zeichen Sie den Constraint-Graph</li>
<li>(2P) Wenden Sie den AC-3-Algorithmus auf das CSP an. Geben Sie den Zustand der Queue und
das Ergebnis von <code>ARC_Reduce</code>, d.h. den Ergebniszustand des aktuellen <span class="math align-center">$D_i$</span>, für jede
Iteration des Algorithmus an.</li>
</ol>
<p><em>Thema</em>: Handsimulation des AC-3-Algorithmus</p>
<h2 id="csp04-forward-checking-und-kantenkonsistenz-2p">CSP.04: Forward Checking und Kantenkonsistenz (2P)</h2>
<p>Betrachten Sie erneut das CSP aus der vorigen Aufgabe und die Zuweisung
<span class="math align-center">$\alpha = \lbrace v_1 \to  2 \rbrace$</span>.</p>
<ol>
<li>
<p>(1P) Erzeugen Sie Kantenkonsistenz in <span class="math align-center">$\alpha$</span>. Geben Sie hierzu die Wertebereiche der
Variablen vor und nach dem Erzeugen der Kantenkonsistenz an.</p>
<p><em>Hinweis</em>: Sie dürfen annehmen, dass der Wertebereich von Variablen mit bereits
zugewiesenen Werten nur aus dem zugewiesenen Wert besteht, während unbelegte Variablen den
vollen Wertebereich haben.</p>
<p><em>Hinweis</em>: Sie müssen zur Lösung dieser Teilaufgabe nicht den AC-3 nutze.</p>
</li>
<li>
<p>(1P) Führen Sie Forward-Checking in <span class="math align-center">$\alpha$</span> aus. Vergleichen Sie das Ergebnis mit (1).</p>
</li>
</ol>
<p><em>Thema</em>: Kantenkonsistenz und Forward Checking verstehen</p>
<h2 id="csp05-anwendungen-1p">CSP.05: Anwendungen (1P)</h2>
<p>Recherchieren Sie, in welchen Anwendungen CSP vorkommen und mit der BT-Suche (plus
Heuristiken) oder sogar AC-3 gelöst werden. Erklären Sie kurz, wie und wofür die Algorithmen
jeweils genutzt werden.</p>
<p><em>Thema</em>: Anwendungen von CSP, BT-Suche und AC-3</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Im Python-Code tauchen immer wieder &quot;TODO&quot;-Marker auf - bitte mit Vorsicht genießen!&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

<article class="default">
<h1>Übungsblatt: Naive Bayes</h1>












    
        <p><strong>(10 Punkte)</strong></p>
    

    <h2 id="nb01-wahlkampf-mit-naive-bayes-4p">NB.01: Wahlkampf mit Naive Bayes (4P)</h2>
<p>Betrachten Sie erneut das Szenerio von <a href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-dtl.html">Aufgabe DTL.01</a>.</p>
<p>(2P) &quot;Trainieren&quot; Sie für den gezeigten Datensatz einen Naive Bayes Klassifikator (manuell).</p>
<p>(2P) Welchen Kandidaten würde der Klassifikator einem Wähler (<span class="math align-center">$< 35$</span>, niedrig, Bachelor)
zuordnen? Erklären Sie die Arbeitsweise des Klassifikators.</p>
<h2 id="nb02-textklassifikation-mit-naive-bayes-spam-erkennung-6p">NB.02: Textklassifikation mit Naive Bayes: Spam-Erkennung (6P)</h2>
<p>Laden Sie sich den Datensatz <a href="https://www.kaggle.com/datasets/venky73/spam-mails-dataset" rel="external" target="_blank">&quot;Spam Mails Dataset&quot; (Kaggle)</a> herunter. Dieser besteht aus
knapp 5000 vorklassifizierten Einträgen (Mails mit den Klassen <code>ham</code> bzw. <code>spam</code>).</p>
<p>(2P) Bereiten Sie diesen Datensatz für das Training eines Naive Bayes Klassifikators vor.
Überlegen Sie sich, was mögliche Merkmale sein könnten und schreiben Sie sich ein Skript,
welches den Datensatz entsprechend bearbeitet/transformiert. (<em>Tipp</em>: Ein <a href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="external" target="_blank">&quot;Bag-of-Words&quot;</a> ist
ein guter Anfang.)</p>
<p>(2P) Implementieren Sie einen Naive Bayes Klassifikator in einer Programmiersprache Ihrer Wahl
oder machen Sie sich mit existierenden Implementierungen vertraut, beispielsweise in <a href="https://www.nltk.org/index.html" rel="external" target="_blank">NLTK</a>
oder <a href="https://scikit-learn.org/stable/index.html" rel="external" target="_blank">scikit-learn</a> oder <a href="https://waikato.github.io/weka-wiki/" rel="external" target="_blank">Weka</a>.</p>
<p>(2P) Splitten Sie den vorbereiteten Datensatz in eine Trainings- und eine Testmenge auf und
trainieren Sie den Naive Bayes Klassifikator. Wie sieht ihr Klassifikator aus, was sind die
wichtigsten Begriffe jeweils für die Klasse <code>spam</code> bzw. <code>ham</code>? Bewerten Sie das Testergebnis.</p>


    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

          </section>
        </div>
      </main>
    </div>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/clipboard.min.js?1737742242" defer></script>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/perfect-scrollbar.min.js?1737742242" defer></script>
    <script>
      function useMathJax( config ){
        window.MathJax = Object.assign( window.MathJax || {}, {
          tex: {
            inlineMath:  [['\\(', '\\)'], ['$',  '$']],  
            displayMath: [['\\[', '\\]'], ['$$', '$$']], 
          },
          options: {
            enableMenu: false 
          }
        }, config );
      }
      useMathJax( JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/mathjax/tex-mml-chtml.js?1737742242"></script>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/theme.js?1737742242" defer></script>
  </body>
</html>
