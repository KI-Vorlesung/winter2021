<!DOCTYPE html>
<html lang="de-DE" dir="ltr" itemscope itemtype="http://schema.org/Article">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.135.0">
    <meta name="generator" content="Relearn 6.4.1">
    <meta name="description" content="Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus dem stetigen Bereich $(0,1)$
Die Hypothesenfunktion ist: $$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 &#43; w_1x_1 &#43; w_2x_2 &#43; \ldots &#43; w_nx_n) \tag{1}$$
Der Kreuzentropie Verlust (engl. Cross-Entropy) für einen Datenpunkt $\mathbf{x}$: $$\mathcal{L}(a, y) = - y \log(a) - (1-y) \log(1-a)\tag{2}$$ wobei hier $a := \hat{y}$ die Vorhersage ist.
Die Kosten als durchschnittlicher Verlust über alle Datenpunkte $x^{(1)}, \ldots, x^{(m)}$: $$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="NN03 - Logistische Regression">
    <meta name="twitter:description" content="Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus dem stetigen Bereich $(0,1)$
Die Hypothesenfunktion ist: $$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 &#43; w_1x_1 &#43; w_2x_2 &#43; \ldots &#43; w_nx_n) \tag{1}$$
Der Kreuzentropie Verlust (engl. Cross-Entropy) für einen Datenpunkt $\mathbf{x}$: $$\mathcal{L}(a, y) = - y \log(a) - (1-y) \log(1-a)\tag{2}$$ wobei hier $a := \hat{y}$ die Vorhersage ist.
Die Kosten als durchschnittlicher Verlust über alle Datenpunkte $x^{(1)}, \ldots, x^{(m)}$: $$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$">
    <meta property="og:url" content="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression.html">
    <meta property="og:title" content="NN03 - Logistische Regression">
    <meta property="og:description" content="Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus dem stetigen Bereich $(0,1)$
Die Hypothesenfunktion ist: $$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 &#43; w_1x_1 &#43; w_2x_2 &#43; \ldots &#43; w_nx_n) \tag{1}$$
Der Kreuzentropie Verlust (engl. Cross-Entropy) für einen Datenpunkt $\mathbf{x}$: $$\mathcal{L}(a, y) = - y \log(a) - (1-y) \log(1-a)\tag{2}$$ wobei hier $a := \hat{y}$ die Vorhersage ist.
Die Kosten als durchschnittlicher Verlust über alle Datenpunkte $x^{(1)}, \ldots, x^{(m)}$: $$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$">
    <meta property="og:locale" content="de_DE">
    <meta property="og:type" content="website">
    <meta itemprop="name" content="NN03 - Logistische Regression">
    <meta itemprop="description" content="Kurze Übersicht Formalisierung Ausgabe $y$ ist reelle Zahl aus dem stetigen Bereich $(0,1)$
Die Hypothesenfunktion ist: $$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 &#43; w_1x_1 &#43; w_2x_2 &#43; \ldots &#43; w_nx_n) \tag{1}$$
Der Kreuzentropie Verlust (engl. Cross-Entropy) für einen Datenpunkt $\mathbf{x}$: $$\mathcal{L}(a, y) = - y \log(a) - (1-y) \log(1-a)\tag{2}$$ wobei hier $a := \hat{y}$ die Vorhersage ist.
Die Kosten als durchschnittlicher Verlust über alle Datenpunkte $x^{(1)}, \ldots, x^{(m)}$: $$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$">
    <meta itemprop="wordCount" content="111">
    <title>NN03 - Logistische Regression</title>
    <link href="https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression.html" rel="canonical" type="text/html" title="NN03 - Logistische Regression">

    

    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/images/logo.png?1737742242" rel="icon" type="image/png">

    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fontawesome-all.min.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fontawesome-all.min.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/nucleus.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/auto-complete.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/auto-complete.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/perfect-scrollbar.min.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fonts.css?1737742242" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/fonts.css?1737742242" rel="stylesheet"></noscript>
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/theme.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/theme-auto.css?1737742242" rel="stylesheet" id="R-variant-style">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/chroma-auto.css?1737742242" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/variant.css?1737742242" rel="stylesheet">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/print.css?1737742242" rel="stylesheet" media="print">
    <link href="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/css/format-print.css?1737742242" rel="stylesheet">
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/variant.js?1737742242"></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='..';
      window.relearn.relBaseUri='..\/..\/..\/..\/..\/..';
      window.relearn.absBaseUri='https:\/\/www.hsbi.de\/elearning\/data\/FH-Bielefeld\/lm_data\/lm_1358898';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.index_js_url="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/index.search.js?1737742242";
      // variant stuff
      window.variants && variants.init( [ 'auto', 'zen-light', 'zen-dark', 'relearn-bright', 'relearn-light', 'relearn-dark' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script><style type="text/css">

 
.center {
    align-content: center;
    text-align: center;
    margin: auto;
}
.alert {
    color: #ff3333;
}
.bsp {
    padding: 0.05cm;
    border-width: 0.05cm;
    border-style: solid;
    border-color: #ddd;
    background-color: #ddd;
    border-radius: 25px;
    float: right;
}
.cbox {
    padding: 0.2cm;
    border-width: 0.1cm;
    border-style: solid;
    border-color: #4070a0;
    background-color: #f2f2f2;
    margin: auto;
    width: 60%;
    text-align: center;
    overflow: auto;
}
.blueArrow {
    color: #4070a0;
    font-family: "Courier New", "Courier", monospace;
    font-weight: bold;
}
.origin {
    background-color: #ededed;
    font-size: 0.8em;
}
.showme {
    background-color: #ededed;
    font-size: 0.8em;
}


 
.tldr {
    background: #dbe4ed;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.recap {
    
    
   margin: 4px 0px 26px 0px;
}
.bib {
    background: #dbe4ed;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.outcomes {
    background: #d9e9d5;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.quizzes {
    background: #d9e9d5;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.challenges {
    background: #ebe4d6;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
.assignments {
    background: #ebe4d6;
    padding: 12px;
    margin: 4px 0px 26px 0px;
}
h1.tldr, h1.recap, h1.bib, h1.outcomes, h1.quizzes, h1.challenges, h1.assignments {
    padding: 0px;
}


 
.noJsAlert {
    padding: 20px;
    background-color: #f44336;  
    color: white;
    margin-bottom: 15px;
}


 
.embed-video-player {
    position: relative;
    padding-bottom: 56%;
    height: 0;
    overflow: hidden;
}
.youtube-player {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border:0;
}


 
#header-wrapper {
    padding:0.6rem;
}


 
#shortcuts {
    padding-top: 2.0rem;
}


 
#chapter p {
    text-align: left;
}


 
figcaption h4 {
    margin-top:-2.5rem;
}
.border1 {
    border:1px solid black;
}

 
td ul, td ol {
    margin: 0 0 1rem 0.5rem;
    padding: 0 0 0 0.5rem;
}

 
h1 { font-size:2.8rem !important;}
h2 { font-size:2.2rem; margin:1.2rem 0}
h3 { font-size:1.9rem; text-align:left !important; font-weight:400 !important;}
h4 { font-size:1.6rem}
h5 { font-size:1.3rem}
h6 { font-size:1rem}

h2 {
    width:100% !important;
    border-bottom:1px solid #5e5e5e !important;
    padding-bottom: 2px;
}
.tldr h2, .recap h2, .bib h2, .outcomes h2, .quizzes h2, .challenges h2, .assignments h2 {
    margin:0.5rem 0
}

.btn-crossreference, .btn-crossreference:hover {
    cursor: initial;
}

</style>

  </head>
  <body class="mobile-support print disableInlineCopyToClipboard" data-url="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
          </div>
          <span class="topbar-breadcrumbs highlightable">
            NN03 - Logistische Regression
          </span>
          <div class="topbar-area topbar-area-end" data-area="end">
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable " tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
<h1>NN03 - Logistische Regression</h1>



    
    
    
    





    
    
        
        
            
        
    
        
        
            
        
    
        
        
            
        
    
        
        
            
        
    
    

    <div class="box notices cstyle info">
  <div class="box-label">
    <i class="fas fa-podcast"></i> Videos
  </div>
  <div class="box-content">
<ul> <li><a href='https://youtu.be/GpJmjrqA5RY' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>NN3.1 - Logistische Regression - Intro</a></li> <li><a href='https://youtu.be/z-jFZeNWMRc' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>NN3.2 - Logistische Regression - Hypothesenfunktion und Bsp</a></li> <li><a href='https://youtu.be/ruuCKupOhCE' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>NN3.3 - Logistische Regression - Verlust und Kosten</a></li> <li><a href='https://youtu.be/kPAZsr-r1LA' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>NN3.4 - Logistische Regression - Gradientenabstieg</a></li></ul>
  </div>
</div>




    
    




    
    
        
        
            
            
                
            
            
        
    
    

    <div class="box notices cstyle info">
  <div class="box-label">
    <i class="far fa-file-powerpoint"></i> Folien
  </div>
  <div class="box-content">
<ul> <li><a href='https://raw.githubusercontent.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/master/lecture/nn/files/NN03-Logistische_Regression.pdf' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>NN03-Logistische_Regression.pdf</a></li></ul>
  </div>
</div>




    <div class="recap">
        <h2 id="kurze-übersicht">Kurze Übersicht</h2>
<h3 id="formalisierung">Formalisierung</h3>
<ul>
<li>
<p>Ausgabe <span class="math align-center">$y$</span> ist reelle Zahl aus dem stetigen Bereich <span class="math align-center">$(0,1)$</span></p>
</li>
<li>
<p>Die <strong>Hypothesenfunktion</strong> ist:
<span class="math align-center">$$h(\mathbf{x}) = \sigma (\mathbf{w}^T\mathbf{x}) = \sigma (w_0 + w_1x_1 + w_2x_2 + \ldots + w_nx_n) \tag{1}$$</span></p>
</li>
<li>
<p>Der <strong>Kreuzentropie Verlust</strong> (engl. Cross-Entropy) für einen Datenpunkt <span class="math align-center">$\mathbf{x}$</span>:
<span class="math align-center">$$\mathcal{L}(a, y) =  - y  \log(a) - (1-y)  \log(1-a)\tag{2}$$</span>
wobei hier <span class="math align-center">$a := \hat{y}$</span> die Vorhersage ist.</p>
</li>
<li>
<p>Die Kosten als durchschnittlicher Verlust über alle Datenpunkte <span class="math align-center">$x^{(1)}, \ldots, x^{(m)}$</span>:
<span class="math align-center">$$J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{3}$$</span></p>
</li>
</ul>
<h3 id="gradientenabstieg">Gradientenabstieg</h3>
<ul>
<li>Der Gradient für einen Datenpunkt <span class="math align-center">$\mathbf{x}$</span>:
<span class="math align-center">$$\frac{\partial \mathcal{L}}{\partial w} = (a-y)x \tag{4}$$</span></li>
<li>Der Gradient für alle Datenpunkte <span class="math align-center">$X$</span> in Matrix-Notation:
<span class="math align-center">$$\nabla J = \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T\tag{5}$$</span></li>
</ul>
<h3 id="graphische-übersicht">Graphische Übersicht</h3>
<ul>
<li>Logistische Regression
<a href="#R-image-f73c03f47130a0951134da48531c4bf1" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/log_reg_nn.png?width=auto&height=auto" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-f73c03f47130a0951134da48531c4bf1"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/log_reg_nn.png?width=auto&height=auto"></a></li>
<li>Lineare Regression
<a href="#R-image-a4bf47a09aa996c559b1d894e9df62f3" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/lin_reg_nn.png?width=auto&height=auto" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-a4bf47a09aa996c559b1d894e9df62f3"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/lin_reg_nn.png?width=auto&height=auto"></a></li>
<li>Perzeptron
<a href="#R-image-5843c1cce2a388efe3ab12a435a8eff1" class="lightbox-link"><img class="noborder lazy lightbox noshadow figure-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/perzeptron_nn.png?width=auto&height=auto" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-5843c1cce2a388efe3ab12a435a8eff1"><img class="noborder lazy lightbox noshadow lightbox-image" loading="lazy" src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/nn/nn03-logistic-regression/perzeptron_nn.png?width=auto&height=auto"></a></li>
</ul>

    </div>

    




    
    
        
        
        

        
            
            
            
        
    
    

    <div class="box notices cstyle note">
  <div class="box-label">
    <i class="fas fa-laptop-code"></i> Übungsblätter/Aufgaben
  </div>
  <div class="box-content">
<ul> <li><a href='https://www.hsbi.de/elearning/data/FH-Bielefeld/lm_data/lm_1358898/homework/sheet-nn-regression.html' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>Übungsblatt: Lineare / Logistische Regression & Gradientenabstieg</a></li></ul>
  </div>
</div>



    

    

    
    
        
        
        
        
    
        
        
        
        
    
        
        
        
        
    
        
        
        
        
    
        
        
        
        
    
    

    <div class="box notices cstyle tip">
  <div class="box-label">
    <i class="fas fa-lightbulb"></i> Lernziele
  </div>
  <div class="box-content">
<ul> <li>(K2) Logistische Regression aus Sicht neuronaler Netze: Graphische Darstellung, Vergleich mit Perzeptron und linearer Regression</li> <li>(K2) Formalisierung</li> <li>(K2) Sigmoid-Aktivierungsfunktion</li> <li>(K2) Verlust- und Kosten (Cross-Entropy Loss)</li> <li>(K3) Gradientenabstieg für logistische Regression</li></ul>
  </div>
</div>



    



    
    
        
        
        
            
        
    
    

    <div class="box notices cstyle tip">
  <div class="box-label">
    <i class="fas fa-user-check"></i> Quizzes
  </div>
  <div class="box-content">
<ul> <li><a href='https://www.hsbi.de/elearning/goto.php?target=tst_1106591&client_id=FH-Bielefeld' class='icon reading' target='_blank' rel='nofollow noopener noreferrer'>Selbsttest Logistische Regression (ILIAS)</a></li></ul>
  </div>
</div>



    



    







<footer class="footline"><div style="color: darkgray; font-size: small;">
<p style="margin-left: 4rem; margin-right: 4rem; margin-top: 6rem;">
<!-- https://creativecommons.org/choose/ -->
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0;margin:0;display:inline;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
Unless otherwise noted, <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung">this work</a> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cyildiz" property="cc:attributionName" rel="cc:attributionURL">Canan Yıldız</a>, <a xmlns:cc="https://creativecommons.org/ns#" href="https://github.com/cagix" property="cc:attributionName" rel="cc:attributionURL">Carsten Gips</a>, and <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/graphs/contributors">contributors</a> is licensed under <a rel="license" href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/LICENSE.md">CC BY-SA 4.0</a>.
See the <a href="https://github.com/Artificial-Intelligence-HSBI-TDU/KI-Vorlesung/blob/master/CREDITS.md">credits</a> for a detailed list of contributing projects.

</p>
</div>

</footer>
</article>

        </div>
      </main>
    </div>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/clipboard.min.js?1737742242" defer></script>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/perfect-scrollbar.min.js?1737742242" defer></script>
    <script>
      function useMathJax( config ){
        window.MathJax = Object.assign( window.MathJax || {}, {
          tex: {
            inlineMath:  [['\\(', '\\)'], ['$',  '$']],  
            displayMath: [['\\[', '\\]'], ['$$', '$$']], 
          },
          options: {
            enableMenu: false 
          }
        }, config );
      }
      useMathJax( JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/mathjax/tex-mml-chtml.js?1737742242"></script>
    <script src="/elearning/data/FH-Bielefeld/lm_data/lm_1358898/js/theme.js?1737742242" defer></script>
  </body>
</html>
